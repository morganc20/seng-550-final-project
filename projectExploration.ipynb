{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-11T21:54:13.819038Z",
     "start_time": "2024-12-11T21:54:13.126322Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import boto3\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "def load_jsonl_from_s3(bucket_name, file_key):\n",
    "    \"\"\"\n",
    "    Load a JSONL file from an S3 bucket using credentials from environment variables.\n",
    "\n",
    "    Parameters:\n",
    "    - bucket_name: str - Name of the S3 bucket.\n",
    "    - file_key: str - Key (path) of the JSONL file in the bucket.\n",
    "\n",
    "    Returns:\n",
    "    - List of Python dictionaries loaded from the JSONL file.\n",
    "    \"\"\"\n",
    "    # Get AWS credentials from environment variables\n",
    "    aws_access_key_id = os.getenv(\"AWS_ACCESS_KEY_ID\")\n",
    "    aws_secret_access_key = os.getenv(\"AWS_SECRET_ACCESS_KEY\")\n",
    "    region_name = os.getenv(\"AWS_REGION\")\n",
    "    \n",
    "    # Initialize an S3 client\n",
    "    s3_client = boto3.client(\n",
    "        's3',\n",
    "        aws_access_key_id=aws_access_key_id,\n",
    "        aws_secret_access_key=aws_secret_access_key,\n",
    "        region_name=region_name\n",
    "    )\n",
    "    \n",
    "    # Retrieve the file content\n",
    "    response = s3_client.get_object(Bucket=bucket_name, Key=file_key)\n",
    "    content = response['Body'].read().decode('utf-8')\n",
    "    \n",
    "    # Parse the JSONL content\n",
    "    data = [json.loads(line) for line in content.splitlines() if line.strip()]\n",
    "    \n",
    "    return data\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    bucket_name = \"small-reviews584\"\n",
    "    file_key = \"data/reviews_small.jsonl\"\n",
    "    \n",
    "    data = load_jsonl_from_s3(bucket_name, file_key)"
   ],
   "id": "fbc121e30a2defb3",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-11T22:03:09.191038Z",
     "start_time": "2024-12-11T22:02:42.098990Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import when, col\n",
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover, HashingTF, IDF\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "# Create a Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"AmazonReviewsLocalLR\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Convert Python list of dicts to Spark DataFrame\n",
    "df = spark.createDataFrame(data)\n",
    "\n",
    "# Ensure the expected columns exist: 'text' for review text and 'rating' for the star rating\n",
    "# If not present, adjust column names accordingly.\n",
    "required_columns = [\"text\", \"rating\"]\n",
    "for col_name in required_columns:\n",
    "    if col_name not in df.columns:\n",
    "        raise ValueError(f\"Expected column '{col_name}' not found in data\")\n",
    "\n",
    "# Create binary label: label=1 if rating >=3 else 0\n",
    "df = df.withColumn(\"label\", when(col(\"rating\") >= 3, 1).otherwise(0))\n",
    "\n",
    "# Filter out rows without text\n",
    "df = df.filter(col(\"text\").isNotNull())\n",
    "\n",
    "# Define text processing and feature extraction pipeline\n",
    "tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"words\")\n",
    "remover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered_words\")\n",
    "hashingTF = HashingTF(inputCol=\"filtered_words\", outputCol=\"rawFeatures\", numFeatures=10000)\n",
    "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\")\n",
    "\n",
    "# Logistic Regression model\n",
    "lr = LogisticRegression(featuresCol=\"features\", labelCol=\"label\", maxIter=20, regParam=0.001)\n",
    "\n",
    "# Create a pipeline for convenience\n",
    "pipeline = Pipeline(stages=[tokenizer, remover, hashingTF, idf, lr])\n",
    "\n",
    "# Split into train and test sets\n",
    "train_df, test_df = df.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "# Fit the model\n",
    "model = pipeline.fit(train_df)\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.transform(test_df)\n",
    "\n",
    "# Evaluate model performance\n",
    "binary_evaluator = BinaryClassificationEvaluator(labelCol=\"label\", rawPredictionCol=\"rawPrediction\", metricName=\"areaUnderROC\")\n",
    "auc = binary_evaluator.evaluate(predictions)\n",
    "\n",
    "multi_evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = multi_evaluator.evaluate(predictions)\n",
    "\n",
    "print(f\"Test AUC: {auc}\")\n",
    "print(f\"Test Accuracy: {accuracy}\")\n",
    "\n",
    "# Stop the Spark session\n",
    "spark.stop()"
   ],
   "id": "87b709a9b8828cf7",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/12/11 15:02:45 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "24/12/11 15:03:01 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test AUC: 0.734489855924728\n",
      "Test Accuracy: 0.8333333333333334\n"
     ]
    }
   ],
   "execution_count": 7
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
